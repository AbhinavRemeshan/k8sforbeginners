# Kubernetes Troubleshooting Guide

## Introduction

Kubernetes, while immensely powerful, can present a variety of challenges during day-to-day operations. From application deployment issues to cluster-level failures, having a structured approach to diagnosing and resolving these problems is essential. This troubleshooting guide aims to assist users in identifying common issues encountered in Kubernetes environments and provides actionable steps to resolve them effectively.

By following this guide, you will gain insights into:
- Diagnosing pod-related issues.
- Investigating cluster health and node failures.
- Resolving networking and service connectivity problems.
- Debugging persistent storage and volume-related errors.
- Troubleshooting authentication and role-based access control (RBAC).

This guide builds upon practical lab exercises to ensure a hands-on understanding of Kubernetes troubleshooting. Use it as a reference for identifying and resolving issues in real-world scenarios. The structure of this document will evolve as we incorporate detailed steps and case studies from provided lab materials.

# Kubernetes Troubleshooting Areas

## Section 1: Troubleshooting Kubernetes Cluster

### Areas to Troubleshoot

- Cluster health and configuration.
- Node statuses and connectivity.
- Namespace-specific issues.

### Possible Scenarios

- The cluster is unresponsive or partially operational.
- Nodes are not in a ready state.
- Namespace-specific issues causing resource unavailability.

### Steps and Commands to Troubleshoot

#### 1. View Nodes in the Cluster

**Command:**

```bash
kubectl get nodes
```

Provides an overview of all nodes and their statuses.

#### 2. Fetch Cluster Information

**Command:**

```bash
kubectl cluster-info
```

Details about the cluster's control plane and components.

#### 3. Obtain a Cluster Dump

**Command:**

```bash
kubectl cluster-info dump
```

Generates diagnostic information about the cluster's state.

#### 4. Explore Dump Command Options

**Command:**

```bash
kubectl cluster-info dump --help
```

Displays available options for generating a cluster dump.

#### 5. Generate Namespace-Specific Dump

**Command:**

```bash
kubectl cluster-info -n <namespace> dump
```

For example, to diagnose issues in the `test` namespace:

```bash
kubectl cluster-info -n test dump
```

#### 6. Check Cluster Component Health

**Command:**

```bash
kubectl get componentstatus
```

Reports the health of cluster components such as etcd, scheduler, and controller-manager.

### Things to Check

- Are all nodes in a `Ready` state?
- Is the control plane accessible using `kubectl cluster-info`?
- Are specific namespaces experiencing issues?
- Are cluster components reporting healthy statuses?

By following these steps, you can effectively diagnose and resolve common Kubernetes cluster issues.

---

## Section 2: Understanding Kubernetes Logging Architecture

### Areas to Troubleshoot

- Application logs and debugging.
- Container-level logging.
- Namespace-wide log aggregation.

### Possible Scenarios

- Logs are not accessible for a specific pod or container.
- Need to debug application behavior using logs.
- Cluster-wide log monitoring requirements.

### Steps and Commands to Troubleshoot

#### Step 1: Get Help with Logging

**Command:**

```bash
kubectl logs --help
```

Displays available options and flags for fetching logs.

#### Step 2: Create a Pod and View Logs

1. Create a YAML file for the pod: **Command:**

   ```bash
   vi busybox.yaml
   ```

   Add the following content to the file:

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: counter
   spec:
     containers:
     - name: count
       image: busybox:1.28
       args: [/bin/sh, -c, 'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']
   ```

2. Deploy the pod and fetch logs: **Command:**

   ```bash
   kubectl apply -f busybox.yaml
   kubectl logs counter
   ```

3. Retrieve the last five lines of logs: **Command:**

   ```bash
   kubectl logs counter --tail=5
   ```

#### Step 3: Advanced Log Options

1. Fetch logs from all containers in a namespace: **Command:**

   ```bash
   kubectl logs counter --all-containers
   ```

2. Fetch logs from a specific time range: **Command:**

   ```bash
   kubectl logs counter --since=<timespan>
   ```

   Example: To retrieve logs from the last hour:

   ```bash
   kubectl logs counter --since=1h
   ```

### Things to Check

- Are logs being generated by the pod/container?
- Is the `kubectl logs` command correctly targeting the pod or namespace?
- Are appropriate log filters, such as `--tail` or `--since`, being applied?

### Tools and Prerequisites

- Tools: `kubectl`, `kubeadm`, `kubelet`, `containerd`.
- Prerequisite: A functioning Kubernetes cluster.

By following these steps, you can effectively monitor and troubleshoot application logs in Kubernetes, ensuring better visibility into system behavior and application performance.

---

## Section 3: Understanding Cluster and Node Logs

### Areas to Troubleshoot

- Control-plane component logs.
- Worker node logs.
- Logs from services like the API server, controller manager, etcd, and kubelet.

### Possible Scenarios

- Control-plane components are unresponsive or showing errors.
- Worker nodes are not functioning as expected.
- Logs are inaccessible or incomplete.

### Steps and Commands to Troubleshoot

#### Step 1: View Control-Plane Component Logs
1. Navigate to the logs directory:
   **Command:**
   ```bash
   cd /var/log/pods
   ls
   ```
   Lists all the components and their directories.

2. Navigate to the API server logs:
   **Command:**
   ```bash
   cd kube-system_kube-apiserver-<master-node>_<unique-id>/kube-apiserver
   ```

3. View the latest log file:
   **Command:**
   ```bash
   ls -la
   sudo cat 0.log
   ```

#### Step 2: View Controller Manager Logs
1. Navigate to the controller manager logs directory:
   **Command:**
   ```bash
   cd kube-system_kube-controller-manager-<master-node>_<unique-id>/kube-controller-manager
   ```

2. View the logs:
   **Command:**
   ```bash
   ls -la
   sudo cat 0.log
   ```

#### Step 3: View etcd Logs
1. Navigate to the etcd logs directory:
   **Command:**
   ```bash
   cd kube-system_etcd-<master-node>_<unique-id>/etcd
   ```

2. View the logs:
   **Command:**
   ```bash
   ls -la
   sudo cat 0.log
   ```

#### Step 4: View Worker Node Logs
1. View the kubelet service logs:
   **Command:**
   ```bash
   sudo journalctl -xu kubelet -n
   ```
   Press `q` to exit the log viewer.

2. View pod logs on the worker node:
   **Command:**
   ```bash
   cd /var/log/pods/
   ls
   ```
   Navigate into specific pod directories to view logs.

### Things to Check

- Are control-plane component logs accessible and free of errors?
- Are kubelet service logs showing any issues on worker nodes?
- Is the logging directory structure consistent across nodes?

### Tools and Prerequisites

- Tools: `kubeadm`, `kubectl`, `kubelet`, `containerd`.
- Prerequisite: A functioning Kubernetes cluster.

By following these steps, you can inspect and troubleshoot control-plane and worker node logs, ensuring smooth cluster operations.

---

## Section 4: Troubleshooting Node Readiness

### Areas to Troubleshoot

- Node readiness and status.
- Kubelet service issues on worker nodes.
- Node transitioning between `Not Ready` and `Ready`.

### Possible Scenarios

- Worker node status shows `Not Ready`.
- Kubelet service on a worker node is inactive or malfunctioning.
- Issues after restarting or disabling a worker node.

### Steps and Commands to Troubleshoot

#### Step 1: Check the Node Status on the Master Node
1. View the status of all nodes in the cluster:
   **Command:**
   ```bash
   kubectl get nodes
   ```

2. Identify the problematic worker node (e.g., `worker-node-2`) from the output.

#### Step 2: Disable the Worker Node and Diagnose
1. Stop the kubelet service on the worker node:
   **Command:**
   ```bash
   sudo service kubelet stop
   ```

2. Verify the kubelet service status:
   **Command:**
   ```bash
   sudo service kubelet status
   ```
   (Press `q` to exit the status viewer.)

3. Check the node's status from the master node after stopping the kubelet service:
   **Command:**
   ```bash
   kubectl get nodes
   ```
   The node status should show `Not Ready`.

4. Describe the node to diagnose the problem:
   **Command:**
   ```bash
   kubectl describe node worker-node-2.example.com
   ```

#### Step 3: Fix the Worker Node
1. Start the kubelet service on the worker node:
   **Command:**
   ```bash
   sudo systemctl start kubelet
   ```

2. Verify the kubelet service status:
   **Command:**
   ```bash
   sudo systemctl status kubelet
   ```
   (Press `q` to exit the status viewer.)

3. After a few minutes, recheck the node's status from the master node:
   **Command:**
   ```bash
   kubectl get nodes
   ```
   The node status should now display `Ready`.

### Things to Check

- Is the kubelet service running correctly on the worker node?
- Are there any errors in the output of `kubectl describe node`?
- Does the node transition back to `Ready` after restarting the kubelet service?

### Tools and Prerequisites

- Tools: `kubeadm`, `kubectl`, `kubelet`, `containerd`.
- Prerequisite: A functioning Kubernetes cluster.

By following these steps, you can successfully diagnose and resolve issues causing a worker node to transition from `Not Ready` to `Ready`.

---


### Section 5: Understanding Container Logs

In this section, you will learn how to check and access container logs using `crictl` commands. These logs are crucial for troubleshooting and understanding container behavior.

#### Steps to Check Container Logs:

1. **Navigate to Worker Node:**
   - Log in to the worker-node-2 in the LMS dashboard.

2. **Fetch the Container ID:**
   - Use the following command to fetch the container ID:
     ```bash
     sudo crictl ps -a
     ```

3. **Access and View Container Logs:**
   - To view the logs of a specific container, use the following command:
     ```bash
     sudo crictl logs <container_id>
     ```
     Replace `<container_id>` with the actual container ID from the previous command.

4. **Retrieve the Latest Log Entry:**
   - If you need to retrieve the most recent log entry, use the following command:
     ```bash
     sudo crictl logs --tail=1 <container_id>
     ```
     This will return the latest log entry for the specified container.

By following these steps, you have successfully demonstrated how to use `crictl` commands to monitor container logs and troubleshoot container-related issues.

---

### Section 6: Analyzing Pod Logs and Troubleshooting Pod Issues

In this section, you will analyze pod logs, troubleshoot common pod and container issues, and explore scenarios such as tainting nodes, incorrect image names, and various pod/container status problems.

---

#### 6.1 Configure and Verify Nginx Deployment

Follow the steps to configure and deploy an Nginx application in Kubernetes.

1. **Create a Configuration File for Nginx Deployment:**
   - Create a file `nginx.yaml` for your Nginx deployment:
     ```bash
     vi nginx.yaml
     ```

   2. **Insert the Nginx Deployment Configuration:**
      Insert the following YAML configuration:
      ```yaml
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        labels:
          app: nginx
        name: nginx
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: nginx
        template:
          metadata:
            labels:
              app: nginx
          spec:
            containers:
            - image: nginx
              name: nginx
      ```

   3. **Create the Nginx Deployment:**
      ```bash
      kubectl create -f nginx.yaml
      ```

   4. **Verify the Deployment and Pod Status:**
      ```bash
      kubectl get deployments
      kubectl get pods
      ```

   5. **View the Logs of the Nginx Pod:**
      ```bash
      kubectl logs nginx-7854ff8877-mvrtr
      ```

---

#### 6.2 Tainting Worker Nodes and Deployment Failures

1. **Taint the Worker Node:**
   - Taint the worker node to prevent any pods from being scheduled on it:
     ```bash
     kubectl taint nodes worker-node-1 key=value:NoSchedule
     ```

2. **Check Deployment Status:**
   - After tainting the node, check the status of the deployment and pods:
     ```bash
     kubectl get deployments
     kubectl get pods
     ```
     **Expected Outcome:** The pod(s) will not be scheduled, and the deployment will not reach the "READY" state.

3. **Troubleshooting the Issue:**
   - To resolve the issue, you can either:
     - Remove the taint from the node:
       ```bash
       kubectl taint nodes worker-node-1 key=value:NoSchedule-
       ```
     - Or, you can add a toleration in your Nginx deployment YAML to allow the pod to be scheduled on tainted nodes:
       ```yaml
       spec:
         template:
           spec:
             tolerations:
             - key: "key"
               operator: "Equal"
               value: "value"
               effect: "NoSchedule"
       ```

---

#### 6.3 Troubleshooting Incorrect Image Names

1. **Use an Incorrect Image Name:**
   - Modify your `nginx.yaml` to use a non-existent image (e.g., `nginx:wrongtag`):
     ```yaml
     containers:
     - image: nginx:wrongtag
       name: nginx
     ```

2. **Check the Pod Status:**
   - After applying the deployment with the incorrect image, check the pod status:
     ```bash
     kubectl get pods
     ```

   **Expected Outcome:** The pod will be stuck in `ImagePullBackOff` or `ErrImagePull` status.

3. **Troubleshoot the Image Pull Error:**
   - To troubleshoot, you can describe the pod to get more information:
     ```bash
     kubectl describe pod nginx-7854ff8877-mvrtr
     ```
     Look for error messages related to the image pull. In this case, it will indicate that the image does not exist.

4. **Fix the Issue:**
   - Update the deployment YAML to use the correct image tag:
     ```yaml
     containers:
     - image: nginx:latest
       name: nginx
     ```

   - Apply the changes:
     ```bash
     kubectl apply -f nginx.yaml
     ```

   - Verify the pod status:
     ```bash
     kubectl get pods
     ```

---

#### 6.4 Pod and Container Status Issues and Fixes

Here are some common pod and container status issues you may encounter, along with troubleshooting steps and fixes.

1. **Pod Status: CrashLoopBackOff**
   - **Cause:** The container within the pod repeatedly crashes (often due to application errors).
   - **Troubleshooting:**
     ```bash
     kubectl describe pod <pod_name>
     kubectl logs <pod_name>
     ```
     - Look for error messages in the logs and investigate the container's behavior.
   - **Fix:** Modify the deployment YAML or the container configuration to fix the application errors. You might need to adjust resource limits, environment variables, or code.

2. **Pod Status: Pending**
   - **Cause:** The pod cannot be scheduled because there are not enough resources available.
   - **Troubleshooting:**
     ```bash
     kubectl describe pod <pod_name>
     ```
     - Check the events section for resource allocation issues.
   - **Fix:** Ensure that the node has enough resources (CPU, memory) or scale up your cluster if necessary.

3. **Pod Status: Terminating**
   - **Cause:** The pod is stuck in the `Terminating` state due to an issue with the deletion process (e.g., finalizers not completing).
   - **Troubleshooting:**
     ```bash
     kubectl get pod <pod_name> -o yaml
     ```
     - Check for the `finalizers` field and any associated issues.
   - **Fix:** Force delete the pod if necessary:
     ```bash
     kubectl delete pod <pod_name> --force --grace-period=0
     ```

4. **Container Status: Waiting (Reason: ContainerCreating)**
   - **Cause:** The container is waiting for necessary resources or dependencies.
   - **Troubleshooting:**
     ```bash
     kubectl describe pod <pod_name>
     ```
     - Check the events section for more information on why the container is stuck in this state.
   - **Fix:** Ensure the required resources (e.g., images, volumes) are available and accessible.

5. **Container Status: Running (but Application is Not Responding)**
   - **Cause:** The container is running, but the application inside it is not behaving as expected (e.g., not starting, crashing).
   - **Troubleshooting:**
     ```bash
     kubectl logs <pod_name> -c <container_name>
     kubectl exec -it <pod_name> -- /bin/bash
     ```
     - Use the logs and interactive shell to investigate the application inside the container.
   - **Fix:** Modify the application configuration, fix any application-level issues, or redeploy the pod.

---

By following these steps, you can troubleshoot various pod and container issues, including node tainting, incorrect image names, and common status problems, ensuring your Kubernetes deployments run smoothly.



